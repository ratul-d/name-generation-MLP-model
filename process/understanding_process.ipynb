{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T07:19:58.747104Z",
     "start_time": "2025-12-28T07:19:58.741577Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cross_entropy"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Understanding Architecture**\n",
    "\n",
    "> **GOAL:** <br>\n",
    "> Given 3 previous characters, predict 4th character  <br>\n",
    "> This system will be our base archictecture that generates names\n",
    "\n",
    "> **NEURAL NETWORK:**  <br>\n",
    "> 6 embeddings ---> 100 neurons (HIDDEN LAYER) ---> 27 neurons (OUTPUT LAYER) <br>\n",
    "* We have 6 embeddings because 2 coming from each previous-character<br>\n",
    "* and 27 neurons in output layer because 26 characters in english + '.' that marks start & end of a name"
   ],
   "id": "4409ae89630813b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Prepare Dataset**",
   "id": "149ffa7a5cf93225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T11:36:22.894319Z",
     "start_time": "2025-12-27T11:36:22.888046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ],
   "id": "2201e69b05821816",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T11:42:41.598028Z",
     "start_time": "2025-12-27T11:42:41.583869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make string to int and reverse mapping\n",
    "chars = sorted(list(set(''.join(words)))) # gets unique chars (a,b,c...,y,z)\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0  # '.' char used to mark the start/end of a name\n",
    "itos = {i:s for s,i in stoi.items()} # reverse mapping\n",
    "\n",
    "stoi"
   ],
   "id": "eca568693c16bfa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T11:54:22.312913Z",
     "start_time": "2025-12-27T11:54:22.303418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build dataset, first 5 names for now\n",
    "# we will use 3 context characters to predict next/4th character\n",
    "# so we are storing X which is the 3 context characters\n",
    "# and Y, the expected character\n",
    "\n",
    "block_size=3\n",
    "X,Y = [],[]\n",
    "for w in words[:5]:\n",
    "    print(w+'.')\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in  context), '--->', itos[ix])\n",
    "        context=context[1:]+[ix]\n",
    "\n",
    "X=torch.tensor(X)\n",
    "Y=torch.tensor(Y)"
   ],
   "id": "8ebd901f552ae1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma.\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> .\n",
      "mm. ---> .\n",
      "olivia.\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> .\n",
      "vi. ---> .\n",
      "ava.\n",
      "... ---> .\n",
      "... ---> v\n",
      "..v ---> .\n",
      ".v. ---> .\n",
      "isabella.\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> .\n",
      "is. ---> b\n",
      "s.b ---> e\n",
      ".be ---> l\n",
      "bel ---> l\n",
      "ell ---> .\n",
      "ll. ---> .\n",
      "sophia.\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> .\n",
      "hi. ---> .\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T11:54:48.449227Z",
     "start_time": "2025-12-27T11:54:48.443856Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape, Y.shape",
   "id": "76db2d141fdc6135",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T11:54:58.787205Z",
     "start_time": "2025-12-27T11:54:58.783028Z"
    }
   },
   "cell_type": "code",
   "source": "X.dtype, Y.dtype",
   "id": "b68b1c938d4ffde4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T12:28:20.410343Z",
     "start_time": "2025-12-27T12:28:20.403541Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "32507408604d1cc2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  4],\n",
       "        [ 0,  4, 12],\n",
       "        [ 4, 12, 12],\n",
       "        [12, 12,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 14],\n",
       "        [ 0, 14, 11],\n",
       "        [14, 11,  8],\n",
       "        [11,  8, 21],\n",
       "        [ 8, 21,  8],\n",
       "        [21,  8,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 21],\n",
       "        [ 0, 21,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  8],\n",
       "        [ 0,  8, 18],\n",
       "        [ 8, 18,  0],\n",
       "        [18,  0,  1],\n",
       "        [ 0,  1,  4],\n",
       "        [ 1,  4, 11],\n",
       "        [ 4, 11, 11],\n",
       "        [11, 11,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 18],\n",
       "        [ 0, 18, 14],\n",
       "        [18, 14, 15],\n",
       "        [14, 15,  7],\n",
       "        [15,  7,  8],\n",
       "        [ 7,  8,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T12:28:20.654859Z",
     "start_time": "2025-12-27T12:28:20.644953Z"
    }
   },
   "cell_type": "code",
   "source": "Y",
   "id": "b39409d6e2d996ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 12, 12,  0,  0, 14, 11,  8, 21,  8,  0,  0,  0, 21,  0,  0,  8, 18,\n",
       "         0,  1,  4, 11, 11,  0,  0, 18, 14, 15,  7,  8,  0,  0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Understanding Embedding/Lookup Table**",
   "id": "a3cb99932f5539bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:45:53.543162Z",
     "start_time": "2025-12-27T18:45:53.529896Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "f410c7c6c93413f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:43:08.835921Z",
     "start_time": "2025-12-27T18:43:08.809303Z"
    }
   },
   "cell_type": "code",
   "source": "C = torch.randn(27,2) # lookup table/embedder",
   "id": "2a6ced33f651351f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:44:04.147739Z",
     "start_time": "2025-12-27T18:44:04.141195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb = C[X] # embedding process\n",
    "emb.shape # output shape"
   ],
   "id": "bc6b29b9897da7d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:45:31.515445Z",
     "start_time": "2025-12-27T18:45:31.510180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# right now emb represents the mapping:  row/record -> index -> embedding\n",
    "# which is why it has shape [32,3,2]\n",
    "\n",
    "# we have to now convert this shape  to [32,6] to be able to multiply with weights of neural network\n",
    "# we do so by using .cat which results in removing the intermediate index\n",
    "# so now mapping is just:  row/record -> embeddings\n",
    "\n",
    "torch.cat( [emb[:,0,:], emb[:,1,:], emb[:,2,:]], 1).shape"
   ],
   "id": "de125ae143939eaf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:53:25.129165Z",
     "start_time": "2025-12-27T18:53:25.119605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this command also does the same thing\n",
    "emb.view(32,6).shape"
   ],
   "id": "31f8aabb28d3fa7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:53:50.661013Z",
     "start_time": "2025-12-27T18:53:50.652018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#verification\n",
    "emb.view(32,6) == torch.cat( [emb[:,0,:], emb[:,1,:], emb[:,2,:]], 1)"
   ],
   "id": "7ae616cac59d98ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:07:53.561146Z",
     "start_time": "2025-12-27T19:07:53.550178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another way, incase we don't know total rows\n",
    "emb.view(-1,6).shape"
   ],
   "id": "d1749d9533bc8fd4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Neural Network**",
   "id": "52f93b251359a525"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:10:38.125315Z",
     "start_time": "2025-12-28T07:10:38.092831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# INITIALIZE NETWORK\n",
    "g = torch.Generator().manual_seed(2147483647) # a fixed seed for consistent results across repeated runs\n",
    "\n",
    "C = torch.randn((27,2), generator=g) # lookup table.embedder\n",
    "W1 = torch.randn((6,100), generator=g) # Hidden layer of 100 neurons that accept 6 inputs each\n",
    "b1 = torch.randn(100, generator=g) # bias\n",
    "W2 = torch.randn((100,27), generator=g) # Output layer of 27 neurons that accept 100 inputs each\n",
    "b2 = torch.rand(27, generator=g) # bias\n",
    "parameters = [C,W1,b1,W2,b2] # trainable parameters"
   ],
   "id": "57a05b67a73a9dbb",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:12:11.244596Z",
     "start_time": "2025-12-28T07:12:11.237394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad=True  # enable gradient tracking for the trainable parameters"
   ],
   "id": "cedbf7d820eb18fc",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:12:53.769815Z",
     "start_time": "2025-12-28T07:12:53.762013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# stat: number of trainable parameters\n",
    "sum(p.nelement() for p in parameters)"
   ],
   "id": "6e8ea2fb25d8aaee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Forward Pass -> Loss Calc -> Backward Pass -> Optimize -> Repeat",
   "id": "97027ac6fecb4e05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:20:08.366941Z",
     "start_time": "2025-12-28T07:20:08.276500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _ in range(100):\n",
    "    # FORWARD PASS\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)  # embeddings passed through HIDDEN layer\n",
    "    logits = h @ W2 + b2 # passed through OUTPUT layer\n",
    "\n",
    "    # LOSS CALCULATION\n",
    "    loss = cross_entropy(logits, Y)  # this is equivalent to applying softmax to logits, then doing negative-log-likelihood loss calculation\n",
    "    print(loss.item())\n",
    "\n",
    "    # zero_grad\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # BACKWARD PASS\n",
    "    loss.backward()\n",
    "\n",
    "    # OPTIMIZE TRAINABLE PARAMETERS\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ],
   "id": "d4f8349db8b19858",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.49248504638672\n",
      "13.841938018798828\n",
      "11.732514381408691\n",
      "10.12384033203125\n",
      "8.868001937866211\n",
      "7.859622478485107\n",
      "6.975170612335205\n",
      "6.202770709991455\n",
      "5.549180030822754\n",
      "5.004162788391113\n",
      "4.532743453979492\n",
      "4.115630149841309\n",
      "3.741363286972046\n",
      "3.407202959060669\n",
      "3.11185359954834\n",
      "2.8486428260803223\n",
      "2.6104061603546143\n",
      "2.3921053409576416\n",
      "2.1899068355560303\n",
      "2.0004918575286865\n",
      "1.8212413787841797\n",
      "1.6508216857910156\n",
      "1.4894375801086426\n",
      "1.3386183977127075\n",
      "1.2007403373718262\n",
      "1.078203797340393\n",
      "0.9725559949874878\n",
      "0.8844568133354187\n",
      "0.8139245510101318\n",
      "0.7594733238220215\n",
      "0.7177218198776245\n",
      "0.6850931644439697\n",
      "0.658933162689209\n",
      "0.6374107599258423\n",
      "0.6192907094955444\n",
      "0.6037342548370361\n",
      "0.5901567339897156\n",
      "0.5781320333480835\n",
      "0.5673421025276184\n",
      "0.5575427412986755\n",
      "0.5485435128211975\n",
      "0.5401943325996399\n",
      "0.532374918460846\n",
      "0.5249898433685303\n",
      "0.5179614424705505\n",
      "0.5112298727035522\n",
      "0.5047483444213867\n",
      "0.4984831213951111\n",
      "0.49241209030151367\n",
      "0.48652365803718567\n",
      "0.480816125869751\n",
      "0.4752947688102722\n",
      "0.4699721932411194\n",
      "0.4648621678352356\n",
      "0.459979385137558\n",
      "0.45533594489097595\n",
      "0.45093995332717896\n",
      "0.446793794631958\n",
      "0.442894846200943\n",
      "0.439236044883728\n",
      "0.4358063340187073\n",
      "0.43259286880493164\n",
      "0.42958083748817444\n",
      "0.426755428314209\n",
      "0.42410165071487427\n",
      "0.42160552740097046\n",
      "0.4192540645599365\n",
      "0.4170350730419159\n",
      "0.4149375557899475\n",
      "0.41295138001441956\n",
      "0.411067396402359\n",
      "0.4092779755592346\n",
      "0.4075753092765808\n",
      "0.40595322847366333\n",
      "0.40440553426742554\n",
      "0.4029270112514496\n",
      "0.40151265263557434\n",
      "0.40015843510627747\n",
      "0.39886006712913513\n",
      "0.39761412143707275\n",
      "0.3964172601699829\n",
      "0.39526644349098206\n",
      "0.3941590189933777\n",
      "0.39309239387512207\n",
      "0.39206427335739136\n",
      "0.39107245206832886\n",
      "0.39011499285697937\n",
      "0.38919010758399963\n",
      "0.3882959485054016\n",
      "0.38743099570274353\n",
      "0.3865940570831299\n",
      "0.3857833743095398\n",
      "0.3849979341030121\n",
      "0.3842364549636841\n",
      "0.3834977149963379\n",
      "0.38278084993362427\n",
      "0.3820849061012268\n",
      "0.3814087510108948\n",
      "0.38075169920921326\n",
      "0.38011297583580017\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Now we do above process but for the whole dataset (all names)**",
   "id": "f7f31b9933b4b961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:32:43.929593Z",
     "start_time": "2025-12-28T07:32:43.500203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build Dataset\n",
    "\n",
    "block_size=3\n",
    "X,Y = [],[]\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context=context[1:]+[ix]\n",
    "\n",
    "X=torch.tensor(X)\n",
    "Y=torch.tensor(Y)"
   ],
   "id": "82a7b2ece7fa2105",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:32:43.939261Z",
     "start_time": "2025-12-28T07:32:43.934133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# INITIALIZE NETWORK\n",
    "g = torch.Generator().manual_seed(2147483647) # a fixed seed for consistent results across repeated runs\n",
    "\n",
    "C = torch.randn((27,2), generator=g) # lookup table.embedder\n",
    "W1 = torch.randn((6,100), generator=g) # Hidden layer of 100 neurons that accept 6 inputs each\n",
    "b1 = torch.randn(100, generator=g) # bias\n",
    "W2 = torch.randn((100,27), generator=g) # Output layer of 27 neurons that accept 100 inputs each\n",
    "b2 = torch.rand(27, generator=g) # bias\n",
    "parameters = [C,W1,b1,W2,b2] # trainable parameters"
   ],
   "id": "b9dd737e689a97fe",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:32:43.945869Z",
     "start_time": "2025-12-28T07:32:43.942668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad=True  # enable gradient tracking for the trainable parameters"
   ],
   "id": "1901bb8ca33f332d",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T07:33:36.774323Z",
     "start_time": "2025-12-28T07:32:44.079289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _ in range(300):\n",
    "    # FORWARD PASS\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)  # embeddings passed through HIDDEN layer\n",
    "    logits = h @ W2 + b2 # passed through OUTPUT layer\n",
    "\n",
    "    # LOSS CALCULATION\n",
    "    loss = cross_entropy(logits, Y)  # this is equivalent to applying softmax to logits, then doing negative-log-likelihood loss calculation\n",
    "    print(loss.item())\n",
    "\n",
    "    # zero_grad\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # BACKWARD PASS\n",
    "    loss.backward()\n",
    "\n",
    "    # OPTIMIZE TRAINABLE PARAMETERS\n",
    "    for p in parameters:\n",
    "        p.data += -0.15 * p.grad\n",
    "\n",
    "print(f\"Final Loss:{loss.item()}\")"
   ],
   "id": "26c634138018656e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.054248809814453\n",
      "15.494484901428223\n",
      "13.760018348693848\n",
      "12.681172370910645\n",
      "11.859382629394531\n",
      "11.208608627319336\n",
      "10.640785217285156\n",
      "10.124303817749023\n",
      "9.648913383483887\n",
      "9.20840072631836\n",
      "8.798007011413574\n",
      "8.416089057922363\n",
      "8.0632963180542\n",
      "7.740719795227051\n",
      "7.448310852050781\n",
      "7.184378147125244\n",
      "6.945443153381348\n",
      "6.727380752563477\n",
      "6.526931285858154\n",
      "6.342012405395508\n",
      "6.171337604522705\n",
      "6.013922691345215\n",
      "5.868598937988281\n",
      "5.733917236328125\n",
      "5.608198165893555\n",
      "5.4899702072143555\n",
      "5.37797737121582\n",
      "5.271376132965088\n",
      "5.169524192810059\n",
      "5.0720696449279785\n",
      "4.978734970092773\n",
      "4.889416694641113\n",
      "4.803995132446289\n",
      "4.7224345207214355\n",
      "4.644629955291748\n",
      "4.5705342292785645\n",
      "4.500037670135498\n",
      "4.433079719543457\n",
      "4.369521617889404\n",
      "4.309239864349365\n",
      "4.25201416015625\n",
      "4.197638034820557\n",
      "4.145840167999268\n",
      "4.096393585205078\n",
      "4.049046516418457\n",
      "4.003616809844971\n",
      "3.9599061012268066\n",
      "3.917792558670044\n",
      "3.8771307468414307\n",
      "3.8378515243530273\n",
      "3.7998459339141846\n",
      "3.763092279434204\n",
      "3.727499008178711\n",
      "3.6930925846099854\n",
      "3.6597766876220703\n",
      "3.6276471614837646\n",
      "3.596562385559082\n",
      "3.5667552947998047\n",
      "3.5379505157470703\n",
      "3.5106992721557617\n",
      "3.484344005584717\n",
      "3.46026349067688\n",
      "3.436652660369873\n",
      "3.4171886444091797\n",
      "3.3964931964874268\n",
      "3.3846869468688965\n",
      "3.3655545711517334\n",
      "3.3661091327667236\n",
      "3.342353343963623\n",
      "3.3580801486968994\n",
      "3.3199610710144043\n",
      "3.3469796180725098\n",
      "3.294419765472412\n",
      "3.3267321586608887\n",
      "3.268343448638916\n",
      "3.3036725521087646\n",
      "3.2435970306396484\n",
      "3.2815184593200684\n",
      "3.2203927040100098\n",
      "3.2605600357055664\n",
      "3.19862699508667\n",
      "3.2406725883483887\n",
      "3.178194999694824\n",
      "3.221766948699951\n",
      "3.158991575241089\n",
      "3.203791856765747\n",
      "3.140872001647949\n",
      "3.1866321563720703\n",
      "3.1237258911132812\n",
      "3.170226573944092\n",
      "3.107482433319092\n",
      "3.1545321941375732\n",
      "3.0920565128326416\n",
      "3.1394970417022705\n",
      "3.077373743057251\n",
      "3.125082015991211\n",
      "3.0633902549743652\n",
      "3.111253023147583\n",
      "3.050037384033203\n",
      "3.0979599952697754\n",
      "3.0373003482818604\n",
      "3.0851993560791016\n",
      "3.0250988006591797\n",
      "3.0729072093963623\n",
      "3.013399839401245\n",
      "3.0610785484313965\n",
      "3.002199411392212\n",
      "3.049699068069458\n",
      "2.9914443492889404\n",
      "3.038717746734619\n",
      "2.981100559234619\n",
      "3.028104305267334\n",
      "2.9711384773254395\n",
      "3.0178587436676025\n",
      "2.9615442752838135\n",
      "3.0079452991485596\n",
      "2.952289342880249\n",
      "2.9983386993408203\n",
      "2.9433398246765137\n",
      "2.989042043685913\n",
      "2.9347150325775146\n",
      "2.9800360202789307\n",
      "2.926353693008423\n",
      "2.971282720565796\n",
      "2.9182488918304443\n",
      "2.9627575874328613\n",
      "2.910400390625\n",
      "2.954484462738037\n",
      "2.9027881622314453\n",
      "2.946436643600464\n",
      "2.895404100418091\n",
      "2.93861722946167\n",
      "2.888235330581665\n",
      "2.930985450744629\n",
      "2.8812522888183594\n",
      "2.9235401153564453\n",
      "2.8744819164276123\n",
      "2.916292905807495\n",
      "2.867891550064087\n",
      "2.9092347621917725\n",
      "2.8614766597747803\n",
      "2.9023399353027344\n",
      "2.8552353382110596\n",
      "2.895624876022339\n",
      "2.849172830581665\n",
      "2.889087677001953\n",
      "2.843266725540161\n",
      "2.882697105407715\n",
      "2.8375027179718018\n",
      "2.8764519691467285\n",
      "2.8318932056427\n",
      "2.870356559753418\n",
      "2.8264195919036865\n",
      "2.8644163608551025\n",
      "2.8210980892181396\n",
      "2.8586196899414062\n",
      "2.8159008026123047\n",
      "2.852959632873535\n",
      "2.810845136642456\n",
      "2.8474373817443848\n",
      "2.8059065341949463\n",
      "2.8420472145080566\n",
      "2.801096200942993\n",
      "2.836789846420288\n",
      "2.7964019775390625\n",
      "2.831651449203491\n",
      "2.7918202877044678\n",
      "2.8266403675079346\n",
      "2.7873544692993164\n",
      "2.8217499256134033\n",
      "2.7829999923706055\n",
      "2.816976547241211\n",
      "2.77874493598938\n",
      "2.812304973602295\n",
      "2.774592638015747\n",
      "2.807753562927246\n",
      "2.7705423831939697\n",
      "2.803309917449951\n",
      "2.7665891647338867\n",
      "2.7989718914031982\n",
      "2.7627344131469727\n",
      "2.794736385345459\n",
      "2.7589633464813232\n",
      "2.7906017303466797\n",
      "2.755284547805786\n",
      "2.786557674407959\n",
      "2.751690626144409\n",
      "2.7826099395751953\n",
      "2.7481722831726074\n",
      "2.778740167617798\n",
      "2.7447397708892822\n",
      "2.774973154067993\n",
      "2.741389274597168\n",
      "2.7712931632995605\n",
      "2.7381131649017334\n",
      "2.767695665359497\n",
      "2.7349159717559814\n",
      "2.7641828060150146\n",
      "2.7317874431610107\n",
      "2.7607431411743164\n",
      "2.728728771209717\n",
      "2.7573845386505127\n",
      "2.725739002227783\n",
      "2.7540977001190186\n",
      "2.7228128910064697\n",
      "2.7508866786956787\n",
      "2.7199530601501465\n",
      "2.747744083404541\n",
      "2.71716046333313\n",
      "2.744678258895874\n",
      "2.7144222259521484\n",
      "2.741672992706299\n",
      "2.7117481231689453\n",
      "2.7387375831604004\n",
      "2.7091245651245117\n",
      "2.735856533050537\n",
      "2.7065556049346924\n",
      "2.7330355644226074\n",
      "2.7040436267852783\n",
      "2.7302801609039307\n",
      "2.7015798091888428\n",
      "2.7275772094726562\n",
      "2.6991682052612305\n",
      "2.7249321937561035\n",
      "2.6967971324920654\n",
      "2.7223317623138428\n",
      "2.69447660446167\n",
      "2.7197864055633545\n",
      "2.6921944618225098\n",
      "2.7172844409942627\n",
      "2.689962148666382\n",
      "2.7148375511169434\n",
      "2.687760353088379\n",
      "2.7124273777008057\n",
      "2.6855998039245605\n",
      "2.7100577354431152\n",
      "2.683476209640503\n",
      "2.7077317237854004\n",
      "2.6813840866088867\n",
      "2.705442428588867\n",
      "2.679328441619873\n",
      "2.7031924724578857\n",
      "2.6773040294647217\n",
      "2.700979232788086\n",
      "2.6753101348876953\n",
      "2.698800563812256\n",
      "2.6733503341674805\n",
      "2.696657180786133\n",
      "2.6714160442352295\n",
      "2.694540500640869\n",
      "2.6695048809051514\n",
      "2.6924548149108887\n",
      "2.667623996734619\n",
      "2.6904006004333496\n",
      "2.6657702922821045\n",
      "2.6883790493011475\n",
      "2.6639418601989746\n",
      "2.686380624771118\n",
      "2.6621346473693848\n",
      "2.6844122409820557\n",
      "2.6603517532348633\n",
      "2.6824703216552734\n",
      "2.6585917472839355\n",
      "2.680549144744873\n",
      "2.656850576400757\n",
      "2.6786534786224365\n",
      "2.655134916305542\n",
      "2.6767873764038086\n",
      "2.6534371376037598\n",
      "2.6749343872070312\n",
      "2.651754856109619\n",
      "2.6731035709381104\n",
      "2.650094985961914\n",
      "2.6712989807128906\n",
      "2.6484577655792236\n",
      "2.6695215702056885\n",
      "2.6468358039855957\n",
      "2.667753219604492\n",
      "2.645228862762451\n",
      "2.666008710861206\n",
      "2.6436383724212646\n",
      "2.6642777919769287\n",
      "2.642066478729248\n",
      "2.6625685691833496\n",
      "2.640507221221924\n",
      "2.6608726978302\n",
      "2.638965368270874\n",
      "2.6591973304748535\n",
      "2.637441396713257\n",
      "2.6575417518615723\n",
      "2.6359305381774902\n",
      "2.655900716781616\n",
      "2.634430170059204\n",
      "2.6542704105377197\n",
      "2.6329472064971924\n",
      "2.6526565551757812\n",
      "2.6314785480499268\n",
      "2.6510634422302246\n",
      "2.6300179958343506\n",
      "2.6494760513305664\n",
      "Final Loss:2.6494760513305664\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e613bfec400b3e24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
